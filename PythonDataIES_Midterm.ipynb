{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Python Midterm - Books version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loading the required libraries\n",
    "import pandas as pd\n",
    "import matplotlib as plt\n",
    "from bs4 import BeautifulSoup\n",
    "import requests\n",
    "from lxml import html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Downloader():\n",
    "    \"\"\"\n",
    "    A class designed to scrape the data based on a provided link\n",
    "    \"\"\"\n",
    "    def __init__(self):\n",
    "        \"\"\"\n",
    "        Initialization\n",
    "        \"\"\"\n",
    "        print('Initialized downloader')\n",
    "        \n",
    "                 \n",
    "    def processTheLink(self,url):\n",
    "        \"\"\"\n",
    "        Processing a given url, assigning url & soupfile\n",
    "        \"\"\"\n",
    "        self.url = url\n",
    "        self.page = requests.get(url)\n",
    "        self.soup = BeautifulSoup(self.page.text,'lxml')\n",
    "        \n",
    "    def getTheLinks(self,soupfile):\n",
    "        \"\"\"\n",
    "        Method gets the required links for the article\n",
    "        \"\"\"\n",
    "        self.tableOfLinks = soupfile.find(\"ol\")\n",
    "        self.urls=[]\n",
    "        for a in self.tableOfLinks.find_all('a', href=True):\n",
    "            #print('https://en.wikipedia.org/' + a['href'])\n",
    "            self.urls.append('https://en.wikipedia.org/'+a['href'])\n",
    "            \n",
    "            \n",
    "class Book():\n",
    "    \n",
    "    def __init__(self):\n",
    "        pass\n",
    "    \n",
    "    def BookInfo(self,url):\n",
    "        \"\"\"\n",
    "        Downloads the info for each book\n",
    "        \"\"\"\n",
    "        self.dic={}\n",
    "        page = requests.get(url)\n",
    "        soup = BeautifulSoup(page.text,'lxml')\n",
    "        #print(url)\n",
    "        tbl = soup.find('table', class_='infobox vcard')\n",
    "        #print(tbl)\n",
    "        trs= tbl.find_all('tr')\n",
    "        #print(trs)\n",
    "        # DOESN'T WORK BECAUSE THE BOOK The Sun Also Rises DOESN'T HAVE INFOBOX VCARD\n",
    "        for tr in trs:\n",
    "            key = tr.find('th')\n",
    "            value = tr.find('td').text\n",
    "            self.dic = {}\n",
    "            for tr in trs:\n",
    "                # first <tr> has no <th> -> error, dealt with nonelegant if statement\n",
    "                if (tr.find('th')!=trs[0].find('th')): \n",
    "                    key = tr.find('th').text\n",
    "                    value = tr.find('td').text\n",
    "                    #print(key,value)\n",
    "                    self.dic[key]=value\n",
    "            \n",
    "            \n",
    "\n",
    "\n",
    "class ScrapedObject(Downloader):\n",
    "    \"\"\"\n",
    "    Class representing scraped object (not sure what it's gonna be yet)\n",
    "    \"\"\"\n",
    "    def __init__(self):\n",
    "        \"\"\"\n",
    "        Initialization\n",
    "        \"\"\"\n",
    "        self.df = df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initialized downloader\n",
      "https://en.wikipedia.org//wiki/Nineteen_Eighty-Four\n",
      "https://en.wikipedia.org//wiki/The_Ambassadors\n",
      "https://en.wikipedia.org//wiki/An_American_Tragedy\n",
      "https://en.wikipedia.org//wiki/Brave_New_World\n",
      "https://en.wikipedia.org//wiki/Catch-22\n",
      "https://en.wikipedia.org//wiki/The_Catcher_in_the_Rye\n",
      "https://en.wikipedia.org//wiki/A_Clockwork_Orange_(novel)\n",
      "https://en.wikipedia.org//wiki/The_Day_of_the_Locust\n",
      "https://en.wikipedia.org//wiki/Finnegans_Wake\n",
      "https://en.wikipedia.org//wiki/The_Grapes_of_Wrath\n",
      "https://en.wikipedia.org//wiki/The_Great_Gatsby\n",
      "https://en.wikipedia.org//wiki/Heart_of_Darkness\n",
      "https://en.wikipedia.org//wiki/The_House_of_Mirth\n",
      "https://en.wikipedia.org//wiki/Invisible_Man\n",
      "https://en.wikipedia.org//wiki/Ironweed_(novel)\n",
      "https://en.wikipedia.org//wiki/Lolita\n",
      "https://en.wikipedia.org//wiki/Midnight%27s_Children\n",
      "https://en.wikipedia.org//wiki/The_Naked_and_the_Dead\n",
      "https://en.wikipedia.org//wiki/Native_Son\n",
      "https://en.wikipedia.org//wiki/On_the_Road\n",
      "https://en.wikipedia.org//wiki/Pale_Fire\n",
      "https://en.wikipedia.org//wiki/A_Passage_to_India\n",
      "https://en.wikipedia.org//wiki/A_Portrait_of_the_Artist_as_a_Young_Man\n",
      "https://en.wikipedia.org//wiki/The_Sheltering_Sky\n",
      "https://en.wikipedia.org//wiki/Slaughterhouse-Five\n",
      "https://en.wikipedia.org//wiki/The_Sound_and_the_Fury\n",
      "https://en.wikipedia.org//wiki/The_Sun_Also_Rises\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'NoneType' object has no attribute 'find_all'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-213-7dc5e49e6486>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      7\u001b[0m     \u001b[0mnew_book\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mBook\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      8\u001b[0m     \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0murl\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 9\u001b[1;33m     \u001b[0mnew_book\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mBookInfo\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0murl\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m<ipython-input-212-635228605937>\u001b[0m in \u001b[0;36mBookInfo\u001b[1;34m(self, url)\u001b[0m\n\u001b[0;32m     44\u001b[0m         \u001b[0mtbl\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0msoup\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfind\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'table'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mclass_\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'infobox vcard'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     45\u001b[0m         \u001b[1;31m#print(tbl)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 46\u001b[1;33m         \u001b[0mtrs\u001b[0m\u001b[1;33m=\u001b[0m \u001b[0mtbl\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfind_all\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'tr'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     47\u001b[0m         \u001b[1;31m#print(trs)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     48\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mtr\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mtrs\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'NoneType' object has no attribute 'find_all'"
     ]
    }
   ],
   "source": [
    "#Initialize downloader\n",
    "dl = Downloader()\n",
    "dl.processTheLink('https://en.wikipedia.org/wiki/20th_Century%27s_Greatest_Hits:_100_English-Language_Books_of_Fiction')\n",
    "dl.getTheLinks(dl.soup)\n",
    "#print(dl.urls)\n",
    "for url in dl.urls:\n",
    "    new_book = Book()\n",
    "    print(url)\n",
    "    new_book.BookInfo(url)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "None\n"
     ]
    }
   ],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Author George Orwell\n",
      "Cover artist Michael Kennard\n",
      "Country United Kingdom\n",
      "Language English\n",
      "Genre Dystopian, political fiction, social science fiction\n",
      "Set in London, Airstrip One, Oceania\n",
      "Publisher Secker & Warburg\n",
      "June 8, 1949; 70 years ago (1949-06-08)\n",
      "Media type Print (hardback and paperback)\n",
      "Pages 328\n",
      "Awards \n",
      "NPR Top 100 Science Fiction and Fantasy Books\n",
      "\n",
      "OCLC 470015866\n",
      "Dewey Decimal 823.912[1]\n"
     ]
    }
   ],
   "source": [
    "### TRIAL FOR ONLY ONE BOOK\n",
    "\n",
    "\n",
    "page = requests.get(dl.urls[0])\n",
    "soup = BeautifulSoup(page.text,'lxml')\n",
    "tbl = soup.find('table', class_='infobox vcard')\n",
    "trs= tbl.find_all('tr')\n",
    "dic = {}\n",
    "for tr in trs:\n",
    "    if (tr.find('th')!=trs[0].find('th')):\n",
    "        key = tr.find('th').text\n",
    "        value = tr.find('td').text\n",
    "        print(key,value)\n",
    "        dic[key]=value\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Author': 'George Orwell',\n",
       " 'Cover\\xa0artist': 'Michael Kennard',\n",
       " 'Country': 'United Kingdom',\n",
       " 'Language': 'English',\n",
       " 'Genre': 'Dystopian, political fiction, social science fiction',\n",
       " 'Set\\xa0in': 'London, Airstrip One, Oceania',\n",
       " 'Publisher': 'Secker & Warburg\\nJune\\xa08, 1949; 70 years ago\\xa0(1949-06-08)',\n",
       " 'Media\\xa0type': 'Print (hardback and paperback)',\n",
       " 'Pages': '328',\n",
       " 'Awards': '\\nNPR Top 100 Science Fiction and Fantasy Books\\n',\n",
       " 'OCLC': '470015866',\n",
       " 'Dewey Decimal': '823.912[1]'}"
      ]
     },
     "execution_count": 189,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {},
   "outputs": [],
   "source": [
    "#print(trs)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
